%\VignetteIndexEntry{Analysis of bead-summary data}
%\VignettePackage{beadarray}
%\VignetteEngine{knitr::knitr}

% To compile this document
% library('knitr'); rm(list=ls()); knit('beadsummary.Rnw')

\documentclass[12pt]{article}
\newcommand{\usecase}{\textit{\textbf{Use Case: }}}

<<knitr, echo=FALSE, results="hide">>=
library("knitr")
opts_chunk$set(tidy=FALSE,dev="png",fig.show="as.is",
               fig.width=10,fig.height=6,
               message=FALSE,eval=FALSE,warning=FALSE,echo=FALSE)
@ 

<<style, eval=TRUE, echo=F, results="asis">>=
BiocStyle::latex()
@
\usepackage{ifthen} 
\newboolean{includethis} 
\setboolean{includethis}{false} 
\newcommand{\ifinclude}[1]{\ifthenelse{\boolean{includethis}}{#1}{}} 



\title{Introduction to Statistical Analysis using R commander}
\author{Sarah Vowler and Mark Dunning \thanks{Acknowledgements: Sarah Dawson and Deepak Parashar}}
\begin{document}
\maketitle
\tableofcontents

\section{Introduction}
In this practical, we will use several 'read-life' datasets to demonstrate some of the concepts you have seen in the lectures. We will guide you through how to analyse these datasets in {\tt Rcmdr} and the kinds of questions you should be asking yourself when faced with similar data.

To answer the questions in this practical we will be using the {\tt R commander} plugin for the {\tt R} statistical package. {\tt R} is a freely-available open-source software that is popular within academic and commercial communities.\footnote{A New York Times article on the emergence of R {\tt http://tinyurl.com/ktw7g5b}}. The functionality within the software compares favourably with other statistical packages (SAS, SPSS and Stata). The downside is that {\tt R} has a steep learning-curve and requires a basic familiarity with command-line software. To ease the transition we have chosen to present this course using a GUI that will allow you to perform statistical analysis without having to worry about learning R. At the same time, the R code required for the analysis will be recorded in the background. You will therefore be able to repeat the analysis at a later date, or pass-on to others. As you gain familiarity with R through other courses, you will see how the code generated by R commander can be adapted to your own needs.

\section{Loading R commander}
The first step is to load {\tt RStudio}. There should be an icon for this on your Desktop.\\
\includegraphics[width=2cm,height=2cm]{images/RStudio.png}

Once loaded, type the following in the 'Console' in the bottom-left where the 'blinking' cursor is; 

<<echo=TRUE>>=
library(Rcmdr)
@

and press Return. A new window should be launched.

You could try exploring some of the available menu options. This practical will not comprehensively cover the usage of R commander, and certainly not {\tt R}. We recommend the following for further documentation about R commander.

{\color{blue}{{\tt http://cran.r-project.org/doc/contrib/Karp-Rcommander-intro.pdf}}}

\section{T-tests practical}

\subsection{The effect of disease on height}
A scientist knows that the mean height of females in England is 165cm and wants to know whether her patients with disease X have heights that differ significantly from the population mean - we will use a one-sample t-test to test this. The data are contained in the file \textit{diseaseX.csv}.

a) What are your null and alternative hypotheses?



\ifinclude{% 
\textbf{Solution:}
{\color{red}
\textit{Null hypothesis: The mean height of female patients with disease X = 165cm (the population mean for females).}

\textit{Alternative hypothesis: The mean height of female patients with disease X $\ne$ 165cm (the population mean for females).}
}
}

To import the file {\tt diseaseX.csv} into {\tt R commander} you will need to follow the menus.\\
{\tt Data} $\rightarrow$ {\tt Import data} $\rightarrow$ {\tt from text file, clipboard, or URL...}\\

The screen that follows allows you to specify various properties of the file that we are trying to import. In this case, we need to select {\tt Commas} as the field separator. You can use the {\tt View data set} button to check that the data has be imported correctly.

<<eval=TRUE, results='asis'>>=
library(Rcmdr)
Disease <- 
  read.table("Course Data/diseaseX.csv",
   header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)

@


b) Create a histogram of the {\tt Height} variable using\\

{\tt Graphs} $\rightarrow$ {\tt Histogram} \\

Do the data look normally distributed? Based on the histogram, is the one-sample t –test appropriate?

<<>>=
with(Disease, Hist(Height, scale="frequency", breaks="Sturges", 
col="darkgray"))
@

\ifinclude{% 
\textbf{Solution:}
{\color{red}
\textit{In this case the data look normally distributed. Therefore, the one-sample t-test is appropriate.}
}
}


c) We are interested in knowing whether the mean height in our sample of patients with disease X is different from that of the general population. Perform a \textbf{one-sample t-test} to test this by selecting \\

{\tt Statistics} $\rightarrow$ {\tt Means} $\rightarrow$ {\tt Single-sample t-test} \\

Remember to change the value of {\tt Null hypothesis: mu = }.

What is the mean height in your sample? What is your value of t? What is the p-value? How do you interpret the p-value?


<<>>=
with(Disease, t.test(Height, alternative='two.sided', mu=165, conf.level=.95))
@

\ifinclude{

\textbf{Solution:}
{\color{red}
Mean height in sample = 171.1cm (95\% CI: 169.3-172.9)
$t = 7.23, 
df = 19,
p \leq 0.0001.$

Under the null hypothesis, the probability of observing a t-statistic as extreme as 7.23, is very small $(P(t \leq 7.23 | t \geq 7.23) < 0.0001)$. Therefore, there is \textbf{strong evidence to reject the null hypothesis in favour of the alternative hypothesis}. There is strong evidence to suggest that the mean height in female patients with disease X is different to the population mean height of females of 165cm.
}
}
\subsection{Biological processes duration}

In the file {\tt wt\_ko\_times.csv}, we have the durations of a biological process for two samples of wild-type and knock-out cells (times in seconds). We are interested in seeing whether there is a difference in the durations for the two types of cells – we shall use an \textbf{independent t-test} to compare the two cell-types.

a) What are your null and alternative hypotheses?

\ifinclude{

\textbf{Solution:}
{\color{red}
\textit{Null hypothesis: there is no difference in the duration of the biological process for the two cell types.}

\textit{Alternative hypothesis: there is a difference in the duration of the biological process for the two cell types. }

}
}
Import the data using the same menu sequence as before\\

{\tt Data} $\rightarrow$ {\tt Import data} $\rightarrow$ {\tt from text file, clipboard, or URL..}\\


b) Create histograms to compare the two groups; {\tt WT} and {\tt KO}. You will need to use the Histogram option as before\\

{\tt Graphs} $\rightarrow$ {\tt Histogram} \\

and select the {\tt Plot by: Group} option.

Do the data look normally distributed for each cell-type? Is the independent t-test appropriate.
<<>>=
Durations <- read.table("Course Data/wt_ko_times.csv", 
header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
with(Durations, Hist(Time, groups=Group, scale="frequency", breaks="Sturges"
                     , col="darkgray"))
@

\textbf{{\color{red}Please note that the histogram by group option is not available in Rcmdr version 2.1.0. You could try and use the Boxplot instead to compare distributions}}
\ifinclude{


\textbf{Solution:}
{\color{red}
\textit{The data do appear to be approximately normally distributed as we could easily draw a bell shape over each of the two histograms. The independent t-test is appropriate.}
}
}

c) Use the Numerical statistics analysis to compute descriptive statistics for each group. \\

{\tt Statistics} $\rightarrow$ {\tt Summaries} $\rightarrow$ {\tt Numerical summaries} \\

Given the distribution of your data, which statistics might you report to summarise your data? Look at and compare the 95\% confidence intervals of the mean durations of the two cell-types.

{\tt Graphs} $\rightarrow$ {\tt Plot of means}\\

Do they overlap?

<<>>=
numSummary(Durations[,"Time"], groups=Durations$Group, 
statistics=c("mean", "sd", "IQR", "quantiles"), quantiles=c(0,.25,
  .5,.75,1))
plotMeans(Durations$Time, Durations$Group, error.bars="conf.int", level=0.95)
@

\ifinclude{


\textbf{Solution:}
{\color{red}
\textit{The normality assumption seems reasonable so the mean and standard deviation (or standard error or 95\% CI) provide a good summary of the data. If the data were skewed, the median and interquartile range would be more meaningful.  The confidence intervals do not overlap.}

}}

d) In order to apply the correct statistical test, we need to test to see if the variances of the two groups are comparable. 

{\tt Statistics} $\rightarrow$ {\tt Variances} $\rightarrow$ {\tt Two-variances F-test}\\

What do you conclude from the p-value of this test. How does it influence what test to use?

<<>>=
var.test(Time ~ Group, alternative='two.sided', conf.level=.95, data=Durations)

@

\ifinclude{


\textbf{Solution:}
{\color{red}
\textit{The test yields a p-value of 0.03568, which is sufficient evidence to reject the null hypothesis that the variances of the two groups are the same. Therefore we should apply Welch's correction.}
}
}

e) Use the appropriate test to compare the durations of the two groups. \\

{\tt Statistics} $\rightarrow$ {\tt Means} $\rightarrow$ {\tt Independent samples t-test}\\

Is a Welch's correction needed? What is your value of t? What is the p-value? How do you interpret the p-value? Is this in agreement with the 95\% confidence intervals?

<<>>=
t.test(Time~Group, alternative='two.sided', 
       conf.level=.95, var.equal=FALSE, data=Durations)
@

\ifinclude{


\textbf{Solution:}
{\color{red}
\textit{When we run the independent (unpaired) t test, a formal comparison of the variances between the two groups is automatically run. The corresponding p-value is 0.00125 which indicates evidence to reject the null hypothesis of equal variances between the two groups. Therefore, Welch's correction is needed. We can also look at the histograms and summary statistics to see whether we might need to use the Welch's correction. We can see that the standard deviation (i.e. spread of data) in each of our groups is quite different (96.63 for WT and 143.94 for KO). The widths of the base of our histograms are also different, though not by a very large amount. Both of these suggest a Welch's correction may be needed.
}
}

}


\subsection{Blood vessel formation}
In blood plasma cancer, there is an increase in blood vessel formation in the bone marrow. A stem cell transplant can be used as a treatment for blood plasma cancer. The bone marrow micro vessel density was measured before and after treatment for 7 patients with blood plasma cancer.

We are interested in seeing whether there is a decrease in the bone marrow micro vessel density after treatment with a stem cell transplant. We will use a paired two-sample t-test to compare the before and after bone marrow micro vessel densities. 

The data are contained in the file {\tt bloodplasmacancer.csv}.

a) What are your null and alternative hypotheses?


\ifinclude{
\textbf{Solution:}
{\color{red}
\textit{Null hypothesis: the bone marrow micro vessel density after treatment is greater than or equal to the bone marrow micro vessel density before treatment. Alternative hypothesis: the bone marrow micro vessel density after treatment is less than the bone marrow micro vessel density before treatment.}

}
}

Import the data and create a column of differences (after-before). 

{\tt Data} $\rightarrow$ {\tt Manage variables in active data set} $\rightarrow$ {\tt Compute new variable}\\

b) Plot a histogram of the differences. Do the data look normally distributed? Is the paired t –test appropriate?

<<>>=
Blood <- read.table("Course Data/bloodplasmacancer.csv", 
  header=TRUE, sep=",", na.strings="NA", dec=".", strip.white=TRUE)
Blood$Diff <- with(Blood, After - Before)
with(Blood, Hist(Diff, scale="frequency", breaks="Sturges", col="darkgray"))
@

\ifinclude{
\textbf{Solution:}
{\color{red}
\textit{From this histogram it is difficult to tell whether the differences between the densities before and after treatment are normally distributed. In situations like this, we may need to draw on the experience of similar sets of measurements. }
}
}

c) We are interested in seeing whether there is a decrease in the bone marrow micro vessel density after treatment with a stem cell transplant. Is this a one-tailed or two-tailed test?

\ifinclude{

\textbf{Solution:}
{\color{red}
\textit{\textbf{One-tailed} as we are only interested in a \textbf{decrease}. Usually a two-sided test is preferred unless there is a strong argument for a one-sided test. In this case our treatment is only considered to be effective if we see a reduction in the bone marrow micro vessel density after treatment. Observing an increase in bone marrow density after treatment would lead to the same action/conclusion as if no difference had been observed – the treatment might be dropped from the research programme (but bear in mind here, the sample size is small and so only large differences may be detected).}
}
}

d) Compare the durations before and after values. Ensure you select the one- or two-tailed test as appropriate. What is the mean difference? What is your value of t? What is the p-value? How do you interpret the p-value? 
<<>>=
t.test(Blood$Before, Blood$After, alternative="greater", conf.level=.95,paired=TRUE)
@

\ifinclude{

\textbf{Solution:}
{\color{red}
\textit{Under the null hypothesis, the probability of observing a t-statistic as extreme as 1.84, is 0.06, slightly greater than 0.05, our nominal significance level. Our result is \textbf{borderline}. There is insufficient evidence to reject the null hypothesis. Therefore, we might conclude that there is an association of a decrease in bone marrow micro vessel density after treatment with bone marrow transplant. It is important to note the small sample size here. Studying just 7 patients means we will only be able to detect large differences. }

}
}
\newpage

\subsection{Saving your work}

For many people, one of the most important features of R is being able to track each step of the analysis and enable the holy grail of \textit{\textbf{Reproducible Research}}. You have probably noticed that each time you select a menu option, the corresponding R code gets recorded within R commander. Not only does this provide a valuable document for yourself if you have to re-visit an analysis in the future, but you can pass you script on to someone else and they would be able to repeat the analysis. A reporting-writing mechanism {\tt 'markdown'} is also provided so that you can write comments about the analysis you have done.

a) Save your R commands to a file

{\tt File} $\rightarrow$ {\tt Save script as} $\rightarrow$

b) Choose the {\tt Generate HTML report} from the {\tt R markdown} tab. Can you see how you might add your own details to the report? The report template can also be saved to disk

{\tt File} $\rightarrow$ {\tt Save R markdown file as} $\rightarrow$


\section{Tests for categorical variables}

\subsection{Nucleotide frequency}
 In \textbf{Table 1}, we have the frequencies of the four nucleotides in two sequences. We are interested in comparing the nucleotide proportions of the two sequences.


a) What are your null and alternative hypotheses?
\begin{table}[h]
\begin{tabular}{l |  l | l | l | l | l| }
  \hline                
  & A & C & G & T & Total \\ \hline
  Sequence 1 & 273 & 233 & 236 & 258 & 1000 \\
  Sequence 2 & 281 & 246 & 244 & 229 & 1000 \\ \hline
  Total & 554 & 479 & 502 & 465 & 2000 \\

\hline  
\end{tabular}
\caption{Nucleotide frequencies for two sequences}
\end{table}

\ifinclude{

\textbf{Solution:}
{\color{red}
\textit{Null hypothesis. there is \textbf{no association} between sequence number and nucleotide.}

\textit{Alternative hypothesis. there is an \textbf{association} between sequence number and nucleotide.}
}
}

Enter the data from \textbf{Table 1} using;\\

{\tt Statistics} $\rightarrow$ {\tt Contingency tables} $\rightarrow$ {\tt Enter and analyze two-way table}\\

You will need to set the number of rows and columns appropriately. \textbf{Note that you do not need to enter the totals.}. Clicking {\tt Ok} will then perform the analysis.

What is your value of your Chi-squared statistic and its corresponding p-value? How do you interpret the result?

<<>>=
.Table <- matrix(c(273,233,236,258,281,246,244,229), 2, 4, byrow=TRUE)

rownames(.Table) <- c('1', '2')

colnames(.Table) <- c('1', '2', '3', '4')

.Table  # Counts

.Test <- chisq.test(.Table, correct=FALSE)

.Test

@
\ifinclude{

\textbf{Solution:}
{\color{red}
$\chi^{2} = \Sexpr{.Test$statistic}, df=3, p = \Sexpr{.Test$p.value}$

\textit{Under the null hypothesis, the probability of observing a Chi-squared statistic as extreme as \Sexpr{.Test$statistic}, is \Sexpr{.Test$p.value}. There is \textbf{no evidence to reject the null hypothesis}. Therefore, there is no evidence of an association between sequence number and nucleotide.}}

}



\subsection{Disease association}
\textbf{Table 2} gives the frequencies of wild-type and knock-out mice developing a disease thought to be associated to the absence of the knock-out gene. 
\begin{table}[h]
\begin{tabular}{l |  l | l | l |}
  \hline                
  & WT & KO &  Total \\ \hline
  Disease & 1 & 7 & 8 \\
  No Disease & 9 & 3 & 12 \\ \hline
  Total & 10 & 10 & 20 \\

\hline  
\end{tabular}
\caption{Frequencies of wild-type and knock-out mice developing disease}
\end{table}

a) What are your null and alternative hypotheses?
\ifinclude{

\textbf{Solution:}
{\color{red}
\textit{Null hypothesis: there is \textbf{no association} between mouse type and disease X}

\textit{Alternative hypothesis: there is an \textbf{association} between mouse type and disease X}
}
}



b) What are your expected frequencies? 

\begin{tabular}{l |  l | l | l |}
  \hline                
  & WT & KO &  Total \\ \hline
  Disease &  &  & 8 \\
  No Disease &  &  & 12 \\ \hline
  Total & 10 & 10 & 20 \\

\hline  
\end{tabular}

\ifinclude{

\textbf{Solution:}
{\color{red}
$Expected~frequency = column~total \times \frac{row~total}{overall~total}$

\begin{tabular}{l |  l | l | l |}
  \hline                
  & WT & KO &  Total \\ \hline
  Disease & 4 & 4 & 8 \\
  No Disease & 6 & 6 & 12 \\ \hline
  Total & 10 & 10 & 20 \\

\hline  
\end{tabular}

}
}
Enter the data as before;\\
{\tt Statistics} $\rightarrow$ {\tt Contingency tables} $\rightarrow$ {\tt Enter and analyze two-way table}\\

c) Select the {\tt Fisher's exact test} option to compare the proportion of mice in each group that developed the disease. What is your p-value? How do you interpret the result?

<<>>=
.Table <- matrix(c(1,7,9,3), 2, 2, byrow=TRUE)
rownames(.Table) <- c('Disease', 'No Disease')
colnames(.Table) <- c('WT', 'KO')
.Table
fisher.test(.Table)


@

\ifinclude{

\textbf{Solution:}
{\color{red}
\textit{p = 0.02. Under the null hypothesis, there is a small probability ($p=0.02<0.05$) of observing such an extreme distribution of the mice given the observed row and column totals. There is \textbf{evidence to reject the null hypothesis in favour of the alternative hypothesis}. There is evidence of an association between mouse type and disease X.}
}
}


\end{document}